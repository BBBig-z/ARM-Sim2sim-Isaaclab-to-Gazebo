seed: 42
device: cuda:0
num_steps_per_env: 36
max_iterations: 1000
empirical_normalization: true
policy:
  class_name: ActorCritic
  init_noise_std: 0
  noise_std_type: scalar
  actor_hidden_dims:
  - 256
  - 128
  critic_hidden_dims:
  - 256
  - 128
  activation: relu
algorithm:
  class_name: PPO
  num_learning_epochs: 8
  num_mini_batches: 512
  learning_rate: 0.001
  schedule: adaptive
  gamma: 0.9
  lam: 0.95
  entropy_coef: 0.005
  desired_kl: 0.01
  max_grad_norm: 0.5
  value_loss_coef: 0.35
  use_clipped_value_loss: true
  clip_param: 0.12
  normalize_advantage_per_mini_batch: false
  symmetry_cfg: null
  rnd_cfg: null
clip_actions: null
save_interval: 200
experiment_name: arm_t_reach_ik
run_name: ''
logger: tensorboard
neptune_project: isaaclab
wandb_project: isaaclab
resume: true
load_run: 2025-10-16_20-57-14
load_checkpoint: model_3000.pt
